深度学习
===
<!--info
toc_id: dl
-->

<!-- TOC -->
- [基础](#基础)
- [模型](#模型)
    - [CNN](#cnn)
    - [RNN](#rnn)
    - [Attention](#attention)
    - [Transformer/BERTs](#transformerberts)
- [专题](#专题)
    - [编程框架](#编程框架)
    - [表示学习](#表示学习)
    - [迁移学习](#迁移学习)
    - [不平衡学习](#不平衡学习)
<!-- TOC -->

---

## 基础
- [激活函数](./_archives/2022/05/激活函数.md)
- [损失函数](./_archives/2022/05/损失函数.md)
- [过拟合与正则化](./_archives/2022/05/过拟合与正则化.md)


## 模型

### CNN
- [CNN基础](./_archives/2022/05/CNN.md)

### RNN
- [RNN基础](./_archives/2022/05/RNN.md)

### Attention
- [常见的Attention计算方法](./_archives/2022/05/Attention.md)

### Transformer/BERTs
- [Transformer/BERT 系列模型](./_archives/2022/05/TransformerWiki.md)
    - [常见面试问题](./_archives/2022/05/Transformer常见问题.md)
- [CRF 在神经网络模型中的作用 (BERT+CRF)](./_archives/2022/05/CRF在神经网络模型中的作用.md)


## 专题

### 编程框架
> [深度学习编程](./_archives/2022/07/深度学习编程.md)

- [使用爱因斯坦标记法操作张量（PyTorch）](./_archives/2022/05/使用爱因斯坦标记法操作张量.md)

### 表示学习
- [基于对比学习的训练框架](./_archives/2022/05/基于对比学习的表示学习训练框架.md)
    - [Sentence-BERT 相关问题整理](./_archives/2022/05/Sentence-BERT论文笔记.md)
- [支持向后兼容的表示学习](./_archives/2022/05/向后兼容的表示学习.md)
- [基于互信息的表示学习](./_archives/2022/05/基于互信息的表示学习.md)（TODO）

### 迁移学习
- [预训练模型的轻量化微调方法](./_archives/2022/05/预训练模型轻量化微调.md)

### 不平衡学习
- [不平衡学习概述](./_archives/2022/05/不平衡学习概述.md)
    - [综述-2019-Johnson](./_archives/2022/05/综述-2019-Johnson.md)
        > 介绍了目前在深度学习中常用的不平衡学习方法，主要包括从数据角度和算法角度提出的方法；
- 论文选读
    - [论文-2022-YiboYang](./_archives/2022/05/论文-2022-YiboYang.md)
        > 基于“神经坍缩”现象，使用**等角紧框架**向量初始化分类头且不参与训练，以缓解不平衡问题
